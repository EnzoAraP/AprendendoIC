"""
SLM - Exemplo Simples e Pr√°tico
================================
Treinamento r√°pido de um Small Language Model para classifica√ß√£o
"""

print("ü§ñ Exemplo Simples de SLM - Classifica√ß√£o de Texto\n")

# Instala√ß√£o necess√°ria (descomente se precisar):
# !pip install transformers datasets torch scikit-learn

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import numpy as np
import os

# ============================================================================
# PASSO 1: Criar dados de treinamento
# ============================================================================

print("üìä PASSO 1: Preparando dados de treinamento\n")

# Dados de exemplo - Classifica√ß√£o de t√≥picos
dados = {
    'texto': [
        # Tecnologia
        "Python √© uma linguagem de programa√ß√£o muito popular",
        "JavaScript √© essencial para desenvolvimento web",
        "Machine learning est√° revolucionando a ind√∫stria",
        "A intelig√™ncia artificial est√° em todo lugar",
        
        # Esportes
        "O time marcou tr√™s gols na partida de ontem",
        "O jogador fez um gol incr√≠vel de falta",
        "O campeonato come√ßa na pr√≥xima semana",
        "A equipe treinou muito para a final",
        
        # Comida
        "Essa pizza estava deliciosa",
        "A receita do bolo √© muito f√°cil",
        "Adoro massas italianas",
        "O restaurante serve comida excelente",
    ],
    'categoria': [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]
    # 0 = Tecnologia, 1 = Esportes, 2 = Comida
}

categorias_nomes = {0: "Tecnologia", 1: "Esportes", 2: "Comida"}

dataset = Dataset.from_dict(dados)
print(f"‚úì Dataset criado: {len(dataset)} exemplos")
print(f"‚úì Categorias: {list(categorias_nomes.values())}\n")

# ============================================================================
# PASSO 2: Carregar modelo pequeno (com treinamento incremental)
# ============================================================================

print("üîß PASSO 2: Carregando modelo\n")

# Verificar se j√° existe um modelo treinado anteriormente
CAMINHO_MODELO_SALVO = "./meu_slm_categorias"

if os.path.exists(CAMINHO_MODELO_SALVO):
    print("üìÇ Modelo anterior encontrado! Continuando treinamento...")
    print("   (Isso vai MELHORAR o modelo existente)\n")
    modelo_nome = CAMINHO_MODELO_SALVO
    eh_continuacao = True
else:
    print("üÜï Primeiro treinamento! Usando modelo base...\n")
    modelo_nome = "distilbert-base-multilingual-cased"
    eh_continuacao = False

tokenizer = AutoTokenizer.from_pretrained(modelo_nome)
modelo = AutoModelForSequenceClassification.from_pretrained(
    modelo_nome,
    num_labels=3  # 3 categorias
)

if eh_continuacao:
    print(f"‚úì Modelo: {CAMINHO_MODELO_SALVO} (Treinamento Cont√≠nuo)")
else:
    print(f"‚úì Modelo: {modelo_nome} (Novo)")
print(f"‚úì Par√¢metros: {modelo.num_parameters():,}\n")

# ============================================================================
# PASSO 3: Preparar dados
# ============================================================================

print("‚öôÔ∏è PASSO 3: Tokenizando dados\n")

def tokenizar(batch):
    return tokenizer(batch['texto'], padding='max_length', truncation=True, max_length=64)

dataset_preparado = dataset.map(tokenizar, batched=True)
dataset_preparado = dataset_preparado.rename_column("categoria", "labels")

print("‚úì Dados tokenizados e prontos!\n")

# ============================================================================
# PASSO 4: Treinar
# ============================================================================

print("üöÄ PASSO 4: Treinando modelo\n")

argumentos = TrainingArguments(
    output_dir="./modelo_categorias",
    num_train_epochs=5,
    per_device_train_batch_size=4,
    learning_rate=3e-5,
    logging_steps=2,
    save_total_limit=1,
)

treinador = Trainer(
    model=modelo,
    args=argumentos,
    train_dataset=dataset_preparado,
)

print("Iniciando treinamento (pode demorar 1-2 minutos)...\n")
treinador.train()
print("\n‚úì Treinamento conclu√≠do!\n")

# ============================================================================
# PASSO 5: Testar
# ============================================================================

print("üß™ PASSO 5: Testando modelo treinado\n")

# Criar pipeline para facilitar as predi√ß√µes
classificador = pipeline(
    "text-classification",
    model=modelo,
    tokenizer=tokenizer
)

# Textos de teste
testes = [
    "Aprendi a programar em Python hoje",
    "O atacante fez um hat-trick",
    "Essa lasanha estava perfeita",
    "Deep learning √© fascinante",
    "O time ganhou de 2 a 0"
]

print("Resultados das predi√ß√µes:")
print("-" * 60)

for texto in testes:
    resultado = classificador(texto)[0]
    label_num = int(resultado['label'].split('_')[1])
    categoria = categorias_nomes[label_num]
    confianca = resultado['score']
    
    print(f"\nüìù Texto: {texto}")
    print(f"‚úì Categoria: {categoria} (Confian√ßa: {confianca:.1%})")

# ============================================================================
# BONUS: Salvar o modelo
# ============================================================================

print("\n" + "=" * 60)
print("üíæ Salvando modelo...")

modelo.save_pretrained(CAMINHO_MODELO_SALVO)
tokenizer.save_pretrained(CAMINHO_MODELO_SALVO)

if eh_continuacao:
    print(f"‚úì Modelo ATUALIZADO e salvo em: {CAMINHO_MODELO_SALVO}")
    print("  (Na pr√≥xima execu√ß√£o, vai continuar melhorando!)")
else:
    print(f"‚úì Modelo NOVO salvo em: {CAMINHO_MODELO_SALVO}")
    print("  (Na pr√≥xima execu√ß√£o, vai usar este como base!)")
print("\n" + "=" * 60)
print("‚ú® Exemplo conclu√≠do com sucesso!")
print("=" * 60)
